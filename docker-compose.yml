services:
  triton:
    image: nvcr.io/nvidia/tritonserver:24.09-py3
    container_name: triton
    restart: unless-stopped
    runtime: nvidia
    shm_size: "1g"
    ulimits:
      memlock: -1
      stack: 67108864
    environment:
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    volumes:
      - ./models:/models
    command: >
      tritonserver
      --model-repository=/models
      --model-control-mode=poll
      --repository-poll-secs=5
      --disable-auto-complete-config=false
      --exit-on-error=false
      --allow-http=true
      --allow-grpc=true
      --metrics-port=8002
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/v2/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 12
